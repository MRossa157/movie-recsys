{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "import implicit\n",
    "from implicit.evaluation import mean_average_precision_at_k\n",
    "from scipy.sparse import coo_matrix\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import constants\n",
    "from utils import train_test_split, MovieEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(r\"..\\MovieLens_20M_Dataset\\rating.csv\")\n",
    "movies = pd.read_csv(r\"..\\MovieLens_20M_Dataset\\movie.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In train propouses we will use only 30% of all ratings dataset\n",
    "rand_userIds = np.random.choice(ratings['userId'].unique(),\n",
    "                                size=int(len(ratings['userId'].unique())*0.3),\n",
    "                                replace=False)\n",
    "\n",
    "ratings = ratings.loc[ratings['userId'].isin(rand_userIds)]\n",
    "print('There are {} rows of data from {} users'.format(len(ratings), len(rand_userIds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the dataset into an implicit feedback dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings.loc[:, 'rating'] = 1\n",
    "\n",
    "train_ratings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_ratings['userId'].values\n",
    "col = train_ratings['movieId'].values\n",
    "data = train_ratings['rating'].values\n",
    "coo_train = coo_matrix((data, (row, col)))\n",
    "coo_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that model works ok with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=10, iterations=2)\n",
    "model.fit(coo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions required for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_user_item_coo(df: DataFrame):\n",
    "    \"\"\" Turn a dataframe with transactions into a COO sparse items x users matrix\"\"\"\n",
    "    row = df['userId'].values\n",
    "    col = df['movieId'].values\n",
    "    data = df['rating'].values\n",
    "    coo = coo_matrix((data, (row, col)))\n",
    "    return coo\n",
    "\n",
    "def get_val_matrices(df: DataFrame):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the following keys:\n",
    "            csr_train: training data in CSR sparse format and as (users x items)\n",
    "            csr_val:  validation data in CSR sparse format and as (users x items)\n",
    "    \"\"\"\n",
    "    df_train, df_test = train_test_split(df)\n",
    "\n",
    "    coo_train = to_user_item_coo(df_train)\n",
    "    coo_test = to_user_item_coo(df_test)\n",
    "\n",
    "    csr_train = coo_train.tocsr()\n",
    "    csr_test = coo_test.tocsr()\n",
    "\n",
    "    return {'csr_train': csr_train,\n",
    "            'csr_test': csr_test\n",
    "          }\n",
    "\n",
    "def validate(matrices: dict, factors=200, iterations=20, regularization=0.01, show_progress=True):\n",
    "    \"\"\" Train an ALS model with <<factors>> (embeddings dimension)\n",
    "    for <<iterations>> over matrices and validate with MAP@30\n",
    "    \"\"\"\n",
    "    csr_train, csr_test = matrices['csr_train'], matrices['csr_test']\n",
    "\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors,\n",
    "                                                 iterations=iterations,\n",
    "                                                 regularization=regularization)\n",
    "    model.fit(csr_train, show_progress=show_progress)\n",
    "\n",
    "    # The MAP@K by implicit doesn't allow to calculate allowing repeated items, which is the case.\n",
    "    map30 = mean_average_precision_at_k(model, csr_train, csr_test, K=30, show_progress=show_progress)\n",
    "    print(f\"Factors: {factors:>3} - Iterations: {iterations:>2} - Regularization: {regularization:4.3f} ==> MAP@30: {map30:6.5f}\")\n",
    "    return map30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = get_val_matrices(ratings)\n",
    "matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "## TQDM initialization\n",
    "# factors_params = [40, 50, 60, 100, 200, 500, 1000]\n",
    "# iter_params = [3, 12, 14, 15, 20]\n",
    "# regularization_params = [0, 0.1, 0.01]\n",
    "\n",
    "# total_iterations = len(factors_params) * len(iter_params) * len(regularization_params)\n",
    "# pbar = tqdm(total=total_iterations, desc=\"Progress\")\n",
    "\n",
    "# best_map30 = 0\n",
    "# for factors in factors_params:\n",
    "#     for iterations in iter_params:\n",
    "#         for regularization in regularization_params:\n",
    "#             map30 = validate(matrices, factors, iterations, regularization, show_progress=False)\n",
    "#             pbar.update(1)\n",
    "#             if map30 > best_map30:\n",
    "#                 best_map30 = map30\n",
    "#                 best_params = {'factors': factors, 'iterations': iterations, 'regularization': regularization}\n",
    "#                 print(f\"Best MAP@30 found. Updating: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дошли до factors = 500 потом слишком долго выполнялся перебор (~80 sec/it при начальных 15 sec/it)\n",
    "best_params = {'factors': 100, 'iterations': 14, 'regularization': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training over the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(r\"..\\MovieLens_20M_Dataset\\rating.csv\")\n",
    "train_ratings, test_ratings = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_train = to_user_item_coo(train_ratings)\n",
    "csr_train = coo_train.tocsr()\n",
    "\n",
    "coo_test = to_user_item_coo(test_ratings)\n",
    "csr_test = coo_test.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(coo_train, factors=200, iterations=15, regularization=0.01, show_progress=True):\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=factors,\n",
    "                                                 iterations=iterations,\n",
    "                                                 regularization=regularization,\n",
    "                                                 random_state=42)\n",
    "    model.fit(coo_train, show_progress=show_progress)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(csr_train, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_average_precision_at_k(model, csr_train, csr_test, K=30, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Zone (смотрим адекватна ли модель или нет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим список пользователей и количества просмотренных ими фильмов\n",
    "user_movie_counts = ratings.groupby('userId')['movieId'].count()\n",
    "users_with_multiple_movies = user_movie_counts[user_movie_counts > 1]\n",
    "users_with_multiple_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из списка выше выберем произвольного пользователя и оценим рекоменадцию \"на глаз\"\n",
    "USERID = 4\n",
    "\n",
    "\n",
    "encoder = MovieEncoder(movie_csv_path=constants.MOVIE_PATH)\n",
    "print('Пользователь просмотрел эти фильмы:')\n",
    "user_viewed_movie_ids = ratings[ratings['userId'] == USERID]['movieId'].values\n",
    "for movieId in user_viewed_movie_ids:\n",
    "    print(encoder.to_title(movieId))\n",
    "print()\n",
    "ids, scores = model.recommend(USERID, csr_train[USERID])\n",
    "print('Мы рекомендуем ему эти')\n",
    "for id, score in zip(ids, scores):\n",
    "    print(encoder.to_title(id), score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
